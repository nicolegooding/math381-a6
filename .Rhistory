as.numeric(length(p_6.0)) * mean(p_6.0) +
as.numeric(length(p_10.2)) * mean(p_10.2))
grandmean <- 5/18 * mean(p_1.6) +
4/18 * mean(p_3.8) +
4/18* mean(p_6.0) +
5/18 * mean(p_10.2)
SS_between <- 5 * (mean(p_1.6) - grandmean)^2 + 4 * (mean(p_3.8) - grandmean)^2 +
4 * (mean(p_6.0) - grandmean)^2 + 5 * (mean(p_10.2) - grandmean)^2
SS_within <- 0
for(i in 1:5) {
SS_within <- SS_within + (p_1.6[i] - mean(p_1.6))^2
}
for(i in 1:4) {
SS_within <- SS_within + (p_3.8[i] - mean(p_3.8))^2
}
for(i in 1:4) {
SS_within <- SS_within + (p_6.0[i] - mean(p_6.0))^2
}
for(i in 1:5) {
SS_within <- SS_within + (p_10.2[i] - mean(p_10.2))^2
}
Fobs <- (SS_between / (4 - 1)) / (SS_within / (18 - 4))
#Regular Chi Squared
obs.counts <- c(14, 28, 44)
p0 <- c(12/54, 17/54, 25/54)
chisq.test(obs.counts, p = p0)$expected
#Chi Squared Independence
obs.counts <- matrix(c(728, 1304, 495, 1072, 2800, 1193), ncol = 3, byrow = T)
chisq.test(obs.counts)
#F test, 1-way ANOVA
dat <- read.table("https://sites.stat.washington.edu/marzban/390/winter21/9_1_dat.txt",
header = TRUE)
aov.1 = aov(Vibration ~ as.factor(Brand), data = dat)
summary(aov.1)
boxplot(Vibration ~ Brand, data = dat)
#Tukey's Test
library(stats)
tuk.1 <- TukeyHSD(aov.1, conf.leve = .99)
tuk.1
plot(tuk.1)
abline(v = 0)
attach(dat)
k <- 5
n <- m <- s <- numeric(k)
for(i in 1:k) {
n[i] <- 6
m[i] <- mean(dat[Brand == i, 2])
s[i] <- sd(dat[Brand == i, 2])
}
df.1 <- k-1
df.2 <- k * 6 - k
SSB <- sum(n * (m - mean(m)) ^ 2)
SSW <- sum(n - 1 * s ^2)
MSB <- SSB / df.1
MSW <- SSW / df.2
F <- MSB/MSW
p.value <- 1 - pf(F, df.1, df.2)
#F test, 1-way ANOVA
dat <- read.table("https://sites.stat.washington.edu/marzban/390/winter21/9_1_dat.txt",
header = TRUE)
attach(dat)
k <- 5
n <- m <- s <- numeric(k)
for(i in 1:k) {
n[i] <- 6
m[i] <- mean(dat[Brand == i, 2])
s[i] <- sd(dat[Brand == i, 2])
}
df.1 <- k-1
df.2 <- k * 6 - k
SSB <- sum(n * (m - mean(m)) ^ 2)
SSW <- sum(n - 1 * s ^2)
MSB <- SSB / df.1
MSW <- SSW / df.2
F <- MSB/MSW
p.value <- 1 - pf(F, df.1, df.2)
df.1 <- k-1
df.2 <- k * 6 - k
SSB <- sum(n * (m - mean(m)) ^ 2)
SSW <- sum((n - 1) * s ^2)
MSB <- SSB / df.1
MSW <- SSW / df.2
F <- MSB/MSW
p.value <- 1 - pf(F, df.1, df.2)
obs.counts <- matrix(c(435, 58, 89, 375, 50, 84), ncol = 3, byrow = T)
View(obs.counts)
obs.counts <- matrix(c(435, 58, 89, 375, 50, 84), ncol = 3, byrow = T)
total <- sum(obs.counts)
rowsum <- apply(obs.counts, 1, sum)
colsum <- apply(obs.counts, 2, sum)
expected <- (matrix(rowsum) %*% t(matrix(colsum))) / total
expected
residuals <- (obs.counts - expected) / sqrt(expected)
df <- prod(dim(obs.counts) - 1)
X2 <- sum(residuals ^ 2)
1 - pchisq(X2, df)
#T and F for regression coefficients
dat1 <- read.table("https://sites.stat.washington.edu/marzban/390/winter21/11_39_dat.txt",
header = TRUE)
plot(dat1, cex = 0.5)
model.1 <- lm(y ~x1 + x2, data = dat1)
summary(model.1)
summary(mode.1)$fstatistic
summary(model.1)$fstatistic
confint(model.1, level= 0.99)
predict(model.1, interval = "confidence", level = 0.95)
predict(model.1, interval = "prediction", level = 0.95)
x <- c(89, 177, 189, 354, 362, 442, 965)
y <- c(.40, .60, .48, .66, .61, .69, .99)
plot(x, y)
plot(x, y)
reg <- lm(y~x)
summary(reg)
reg <- lm(y~log(x))
summary(reg)
meanx <- mean(x)
meany <- mean(y)
Sxx <- sum((x-meanx)^2)
Sxy <- sum((x-meanx)(y - meany))
x-meanx
(x-meanx)^2
sum((x-meanx)^2)
Sxy <- sum((x-meanx) * (y - meany))
beta <- Sxy / Sxx
aov(y~x)
summary(aov(y~x))
summary(reg)
reg$residuals
sum(reg$residuals)
sqrt(sum(reg$residuals)^2 / 5)
Se <- sqrt(sum(reg$residuals)^2 / (as.numeric(length(y)) - (1+1)))
reg <- lm(y~(x))
Sxx <- sum((x-meanx)^2)
Sxy <- sum((x-meanx) * (y - meany))
beta <- Sxy / Sxx
Se <- sqrt(sum(reg$residuals)^2 / (as.numeric(length(y)) - (1+1)))
reg$coefficients[2]
yhat <- reg$coefficients[2](x) + reg$coefficients[1]
yhat <- reg$coefficients[2] * (x) + reg$coefficients[1]
sqrt(sum((y-yhat)^2) / 5)
sqrt(sum((y-yhat)^2 / 5))
reg$residuals - (y-yhat)
Se <- sqrt(sum(reg$residuals^2 / (as.numeric(length(y)) - (1+1))))
summary(reg)
qt(.95, 5)
qt(.95, 5, lower.tail = TRUE)
qt(.95, 5, lower.tail = FALSE)
Sxx <- sum((x-meanx)^2)
Sxy <- sum((x-meanx) * (y - meany))
beta <- Sxy / Sxx
Se <- sqrt(sum(reg$residuals^2 / (as.numeric(length(y)) - (1+1))))
Sxx
Se
yhat_250 <- reg$coefficients[2] * 250 + reg$coefficients[1]
Sesterror <- Se * sqrt(1/as.numeric(length(y)) + (250 - meanx) ^2 / Sxx)
yhat_250 + (2.571 * Sesterror)
yhat_250 - (2.571 * Sesterror)
yhat_250 <- reg$coefficients[2] * 250 + reg$coefficients[1]
Syhat <- Se * sqrt(1/as.numeric(length(y)) + (250 - meanx) ^2 / Sxx)
yhat_250 + (2.571 * sqrt(Syhat^2 + Se^2))
yhat_250 - (2.571 * sqrt(Syhat^2 + Se^2))
clear
source('~/Desktop/Autumn 2021/Info 201/lecture4.R')
get_circumference(10)
source('~/Desktop/Autumn 2021/Info 201/lecture4.R')
greeting(Mollie)
greeting("Mollie")
source('~/Desktop/Autumn 2021/Info 201/lecture4.R')
greeting("Mollie")
greeting("Mollie")
source('~/Desktop/Autumn 2021/Info 201/lecture4.R')
get_pairity(2)
get_pairity(5)
get_pairity(0)
source('~/Desktop/Autumn 2021/Info 201/lecture4.R')
source('~/Desktop/Autumn 2021/Info 201/lecture4.R')
coffee(10, 2)
coffee(1, 5)
coffee(2,2)
get_pairity(-2)
get_pairity(-1739879877)
M <- 10
transition_matrix <- matrix(M, M, 0)
View(transition_matrix)
transition_matrix <- matrix(0, M, M)
View(transition_matrix)
transition_matrix <- matrix(0, M+1, M+1)
for(i in 1:M+1){
if(i <= 6 || i>= 1){
transition_matrix[0,1] <- 1/6
}
}
View(transition_matrix)
for(i in 1:M+1){
if(i <= 6 || i>= 1){
transition_matrix[0,i] <- as.numeric(1/6)
}
}
for(i in 1:M+1){
if(i <= 6 || i>= 1){
transition_matrix[1,i] <- as.numeric(1/6)
}
}
for(i in 1:M+1){
if(i <= 6 && i>= 1){
transition_matrix[1,i] <- as.numeric(1/6)
}
}
for(i in 1:M+1){
if(i <= 7 & i >= 0){
transition_matrix[1,i] <- as.numeric(1/6)
}
}
for(i in 1:M+1){
if(i <= 7 && i >= 0){
transition_matrix[1, i] <- as.numeric(1/6)
}
}
prob <- as.numeric(1/6)
if(i <= 7 && i >= 1){
transition_matrix[1, i] <- prob
}
transition_matrix <- matrix(0, M+1, M+1)
for(i in 1:M+1){
if(i <= 7 && i >= 1){
transition_matrix[1, i] <- prob
}
}
View(transition_matrix)
library(tidyverse)
# Load the *national level* data into a variable. `national`
# (hint: you'll need to get the "raw" URL from the NYT GitHub page)
national <- read.csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us.csv")
# Load the *state level* data into a variable. `states`
states <- read.csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")
# Load the *county level* data into a variable. `counties`
# (this is a large dataset, which may take ~30 seconds to load)
counties <- read.csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv")
# How many observations (rows) are in each dataset?
# Create `obs_national`, `obs_states`, `obs_counties`
obs_national <- nrow(national_df)
obs_states <- nrow(states_df)
obs_counties <- nrow(counties_df)
# Reflection: What does each row represent in each dataset?
# How many features (columns) are there in each dataset?
# Create `num_features_national`, `num_features_states`, `num_features_counties`
num_features_national <- ncol(national_df)
num_features_states <- ncol(states_df)
num_features_counties <- ncol(counties_df)
# Exploratory analysis ----------------------------------------------------
# For this section, you should explore the dataset by answering the following
# questions. HINT: Remeber that in class, we talked about how you can answer
# most data analytics questions by selecting specific columns and rows.
# For this assignemnt, you are welcome to use either base R dataframe indexing or
# use functions from the DPLYR package (e.g., using `pull()`). Regardless, you
# must return the specific column being asked about. For example, if you are
# asked the *county* with the highest number of deaths, your answer should
# be a single value (the name of the county: *not* an entire row of data).
# (again, make sure to read the documentation to understand the meaning of
# each row -- it isn't immediately apparent!)
library(dplyr)
# How many total cases have there been in the U.S. by the most recent date
# in the dataset? `total_us_cases`
total_us_cases <- max(select(national_df, cases))
# How many total deaths have there been in the U.S. by the most recent date
# in the dataset? `total_us_deaths`
total_us_deaths <- max(select(national_df, deaths))
# Which state has had the highest number of cases?
# `state_highest_cases`
max_state_case <-max(select(states_df, cases))
state_highest_cases <- first(select(
filter(states_df, cases == max_state_case),
state))
# What is the highest number of cases in a state?
# `num_highest_state`
num_highest_state <- max_state_case
# Which state has the highest ratio of deaths to cases (deaths/cases), as of the
# most recent date? `state_highest_ratio`
# (hint: you may need to create a new column in order to do this!)
states_df <- mutate(states_df, ratio = as.numeric(deaths)/cases)
# Which state has had the lowest number of cases *as of the most recent date*?
# (hint, this is a little trickier to calculate than the maximum because
# of the meaning of the row). `state_lowest_cases`
last_day <- first(summarise(states_df, max_day = max(as.Date(date))))
last_day_numbers <- filter(states_df, date == last_day)
min_cases <-  min(select(last_day_numbers, cases))
state_lowest_cases <- first(select(
filter(last_day_numbers, cases == min_cases), state))
source('~/Desktop/Autumn 2021/Info 201/assignment-2-us-covid-trends-nicolegooding/analysis.R', echo=TRUE)
# Which county has had the highest number of cases?
# `county_highest_cases`
county_highest_cases_num <- max(counties$cases)
county_highest_cases <- first(select
(filter(counties, cases == county_highest_cases_num),
county))
View(counties)
# What is the highest number of cases that have happened in a single county?
# `num_highest_cases_county`
num_highest_cases_county <- county_highest_cases_num
# Because there are multiple counties with the same name across states, it
# will be helpful to have a column that stores the county and state together
# (in the form "COUNTY, STATE").
# Add a new column to your `counties` data frame called `location`
# that stores the county and state (separated by a comma and space).
# You can do this by mutating a new column, or using the `unite()` function
# (just make sure to keep the original columns as well)
counties <- mutate(counties, location = paste(county, state, sep = ", "))
max_deaths <- max(counties$deaths)
location_most_deaths <- first(select
(filter(counties, deaths == max_deaths),
location))
# What is the name of the location (county, state) with the highest number
# of deaths? `location_most_deaths`
max_deaths <- max(na.omit(counties$deaths))
location_most_deaths <- first(select
(filter(counties, deaths == max_deaths),
location))
0-NA
national <- mutate(national, new_cases =
cases-lag(national, 1))
# At this point, you (hopefully) have realized that the `cases` column *is not*
# the number of _new_ cases in a day (if not, you may need to revisit your work)
# Add (mutate) a new column on your `national` data frame called `new_cases`
# that has the nubmer of *new* cases each day (hint: look for the `lag`
# function).
national <- mutate(national, new_cases =
select(nationals, cases) -lag(national, order_by = as.Date(date)))
# At this point, you (hopefully) have realized that the `cases` column *is not*
# the number of _new_ cases in a day (if not, you may need to revisit your work)
# Add (mutate) a new column on your `national` data frame called `new_cases`
# that has the nubmer of *new* cases each day (hint: look for the `lag`
# function).
national <- mutate(national, new_cases =
select(national, cases) -lag(national, order_by = as.Date(date)))
lag(national, order_by = as.Date(date)
# At this point, you (hopefully) have realized that the `cases` column *is not*
# the number of _new_ cases in a day (if not, you may need to revisit your work)
# Add (mutate) a new column on your `national` data frame called `new_cases`
# that has the nubmer of *new* cases each day (hint: look for the `lag`
# function).
prev_cases <- lag(national, order_by = as.Date(date)
national <- mutate(national, new_cases =
select(national, cases) - ))
# At this point, you (hopefully) have realized that the `cases` column *is not*
# the number of _new_ cases in a day (if not, you may need to revisit your work)
# Add (mutate) a new column on your `national` data frame called `new_cases`
# that has the nubmer of *new* cases each day (hint: look for the `lag`
# function).
prev_cases <- lag(national, order_by = as.Date(date)
View(prev_cases)
# At this point, you (hopefully) have realized that the `cases` column *is not*
# the number of _new_ cases in a day (if not, you may need to revisit your work)
# Add (mutate) a new column on your `national` data frame called `new_cases`
# that has the nubmer of *new* cases each day (hint: look for the `lag`
# function).
prev_cases <- lag(national, order_by = as.Date(date))
View(national)
# At this point, you (hopefully) have realized that the `cases` column *is not*
# the number of _new_ cases in a day (if not, you may need to revisit your work)
# Add (mutate) a new column on your `national` data frame called `new_cases`
# that has the nubmer of *new* cases each day (hint: look for the `lag`
# function).
prev_cases <- lag(national)
View(prev_cases)
# At this point, you (hopefully) have realized that the `cases` column *is not*
# the number of _new_ cases in a day (if not, you may need to revisit your work)
# Add (mutate) a new column on your `national` data frame called `new_cases`
# that has the nubmer of *new* cases each day (hint: look for the `lag`
# function).
prev_cases <- lag(national)$cases
national <- mutate(national, new_cases = select(national, cases) - lag(national)$cases)
View(national)
national <- mutate(national, new_cases = (select(national, cases) - lag(national)$cases))
national <- mutate(national, new_cases = (select(national, cases) - prev_cases))
national <- mutate(national, new_cases = (cases - prev_cases))
national$new_cases[1] = 0
rename(national, new_cases = new_cases.cases)
View(national)
prev_deaths <- lag(national)$deaths
national <- mutate(national, new_deaths = deaths - prev_deaths)
national$new_deaths[1]=0
max_new_cases <- max(national$new_cases)
date_most_cases <- first(select(
filter(national, new_cases == max_new_cases), date
))
date_most_cases
source('~/Desktop/Autumn 2021/Info 201/assignment-2-us-covid-trends-nicolegooding/analysis.R', echo=TRUE)
# Load the *national level* data into a variable. `national`
# (hint: you'll need to get the "raw" URL from the NYT GitHub page)
national <- read.csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us.csv")
total_us_cases <- max(select(national, cases))
# How many total deaths have there been in the U.S. by the most recent date
# in the dataset? `total_us_deaths`
total_us_deaths <- max(select(national, deaths))
# At this point, you (hopefully) have realized that the `cases` column *is not*
# the number of _new_ cases in a day (if not, you may need to revisit your work)
# Add (mutate) a new column on your `national` data frame called `new_cases`
# that has the nubmer of *new* cases each day (hint: look for the `lag`
# function).
prev_cases <- lag(national)$cases
national <- mutate(national, new_cases = (cases - prev_cases))
source('~/Desktop/Autumn 2021/Info 201/assignment-2-us-covid-trends-nicolegooding/analysis.R', echo=TRUE)
max_new_deaths <- max(national$new_deaths)
date_most_deaths <- first(select(filter(national, new_deaths == max_new_deaths),
date))
last_day_numbers_states <- filter(states, date == last_day)
last_day_states <- first(summarise(states, max_day = max(as.Date(date))))
last_day_numbers_states <- filter(states, date == last_day)
# What is the county with the *current* (e.g., on the most recent date)
# highest number of cases in each state? Your answer, stored in
# `highest_in_each_state`, should be a *vector* of
# `location` names (the column with COUNTY, STATE).
# Hint: be careful about the order of filtering your data!
last_day_counties <- first(summarise(counties, max_day = max(as.Date(date))))
last_day_counties_df <- filter(counties, as.Date(date)==last_day_counties)
View(last_day_counties_df)
max_county_count_state %>% group_by(state) %>% summarise(most_cases = max(cases))
max_county_count_state <- last_day_counties_df %>% group_by(state) %>% summarise(most_cases = max(cases))
View(max_county_count_state)
highest_in_each_state <- select(filter(last_day_counties_df, state == max_county_count_state$state,
cases == max_county_count_state$most_cases))
max_county_count_state <- last_day_counties_df %>% group_by(state) %>% mutate(most_cases = max(cases))
# Load the tidyverse package
library(tidyverse)
# For this section, you should explore the dataset by answering the following
# questions. HINT: Remeber that in class, we talked about how you can answer
# most data analytics questions by selecting specific columns and rows.
# For this assignemnt, you are welcome to use either base R dataframe indexing or
# use functions from the DPLYR package (e.g., using `pull()`). Regardless, you
# must return the specific column being asked about. For example, if you are
# asked the *county* with the highest number of deaths, your answer should
# be a single value (the name of the county: *not* an entire row of data).
# (again, make sure to read the documentation to understand the meaning of
# each row -- it isn't immediately apparent!)
library(dplyr)
max_county_count_state <- last_day_counties_df %>% group_by(state) %>% mutate(most_cases = max(cases))
View(max_county_count_state)
highest_in_each_state <- select(filter(last_day_counties_df, cases == most_cases), location)
highest_in_each_state <- select(filter(max_county_count_state, cases == most_cases), location)
View(highest_in_each_state)
last_day_counties_df <- last_day_counties_df %>% group_by(state) %>% mutate(most_cases = max(cases))
highest_in_each_state <- select(filter(last_day_counties_df, cases == most_cases), location)$location
View(max_county_count_state)
last_day_counties <- first(summarise(counties, max_day = max(as.Date(date))))
last_day_counties_df <- filter(counties, as.Date(date)==last_day_counties)
max_county_count_state <- last_day_counties_df %>% group_by(state) %>% mutate(most_cases = max(cases))
highest_in_each_state <- select(filter(max_county_count_state, cases == most_cases),
state, location)$location
View(last_day_counties_df)
lowest_in_each_state <- select(filter(min_county_count_state, cases == least_cases),
state, location)$location
min_county_count_state <- last_day_counties_df %>% group_by(state) %>% mutate(least_cases = min(cases))
lowest_in_each_state <- select(filter(min_county_count_state, cases == least_cases),
state, location)$location
View(min_county_count_state)
View(min_county_count_state)
setwd("~/Desktop/Autumn 2021/Math 381/A6")
test <- read.csv("runs.csv")
View(test)
test <- read.csv("runs.csv", header = F);
View(test)
test <- read.csv("runs.csv", header = F);
test <- read.csv("runs.csv", header = F);
library(tidyverse)
library(tidyverse)
library(dplyr)
library(plotly)
data<- read.csv("athlete_events copy.csv")
data <- mutate(data, gold = if_else(!is.na(Medal) & Medal == "Gold", 1, 0),
silver = if_else(!is.na(Medal) & Medal == "Silver", 1, 0),
bronze = if_else(!is.na(Medal) & Medal == "Bronze", 1, 0))
by_athlete <- data %>% group_by(Name) %>% summarise(Weight = mean(Weight), Height = mean(Height),
Gold = sum(gold), Silver = sum(silver),
Bronze = sum(bronze))
by_athlete <- filter(by_athlete, !is.na(Weight) & !is.na(Height))
by_athlete <- mutate(by_athlete, BMI = Weight/(Height^2)*10000)
gold_medal_athletes <- filter(by_athlete, Gold>0)
fig <- plot_ly(data = gold_medal_athletes, x = ~Height, y = ~Weight, type = "scatter",
mode = 'markers', marker = list(size = 3)) %>%
layout(title = 'Height vs Weight of Olympic Gold Medal Athletes from 1896 to 2016')
fig
setwd("~/Desktop/Autumn 2021/Info 201/In Class Exercises")
by_athlete <- data %>% group_by(Name) %>% summarise(Weight = mean(Weight), Height = mean(Height),
Gold = sum(gold), Silver = sum(silver),
Bronze = sum(bronze))
library(tidyverse)
library(dplyr)
library(plotly)
data<- read.csv("athlete_events copy.csv")
data <- mutate(data, gold = if_else(!is.na(Medal) & Medal == "Gold", 1, 0),
silver = if_else(!is.na(Medal) & Medal == "Silver", 1, 0),
bronze = if_else(!is.na(Medal) & Medal == "Bronze", 1, 0))
by_athlete <- data %>% group_by(Name) %>% summarise(Weight = mean(Weight), Height = mean(Height),
Gold = sum(gold), Silver = sum(silver),
Bronze = sum(bronze))
by_athlete <- filter(by_athlete, !is.na(Weight) & !is.na(Height))
by_athlete <- mutate(by_athlete, BMI = Weight/(Height^2)*10000)
gold_medal_athletes <- filter(by_athlete, Gold>0)
fig <- plot_ly(data = gold_medal_athletes, x = ~Height, y = ~Weight, type = "scatter",
mode = 'markers', marker = list(size = 3)) %>%
layout(title = 'Height vs Weight of Olympic Gold Medal Athletes from 1896 to 2016')
fig
View(data)
setwd("~/Desktop/Autumn 2021/Math 381/math381-a6")
test1 <- read.csv("convergence.csv")
test2 <- read.csv("histogram.csv")
View(test1)
View(test1)
View(test2)
test1 <- read.csv("convergence.csv")
test2 <- read.csv("histogram.csv")
View(test1)
